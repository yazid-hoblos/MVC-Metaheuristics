\documentclass[12pt,a4paper]{article}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{geometry}
\usepackage{hyperref}
\geometry{margin=1in}

\lstset{
    language=Python,
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    stringstyle=\color{gray},
    commentstyle=\color{gray},
    keywordstyle=\color{blue},
    showstringspaces=false,
    frame=single,
    captionpos=b,
    numbers=left,
    numberstyle=\tiny
}

\title{Appendix: Minimum Vertex Cover Optimization\\
Pseudocode and Implementation Details}
\date{\today}

\begin{document}

\maketitle

\section{Algorithm Pseudocode}

\subsection{Genetic Algorithm}

\textbf{Algorithm 1: Genetic Algorithm for Minimum Vertex Cover}

\begin{verbatim}
procedure GeneticAlgorithm(problem, encoding, fitness, params)
  population ← InitializePopulation(params.population_size, encoding)
  best_solution ← None
  best_fitness ← -∞
  
  for generation = 1 to params.generations do
    fitness_scores ← EvaluatePopulation(population, fitness)
    gen_best ← ArgMax(fitness_scores)
    
    if fitness_scores[gen_best] > best_fitness then
      best_fitness ← fitness_scores[gen_best]
      best_solution ← DeepCopy(population[gen_best])
    end if
    
    elites, elite_fitness ← SelectElites(population, fitness_scores, params.elitism_rate)
    new_population ← elites
    
    while Length(new_population) < params.population_size do
      parent1 ← Selection(population, fitness_scores, params.selection_type)
      parent2 ← Selection(population, fitness_scores, params.selection_type)
      
      if Random() < params.crossover_rate then
        child1, child2 ← Crossover(parent1, parent2, encoding)
      else
        child1 ← DeepCopy(parent1)
        child2 ← DeepCopy(parent2)
      end if
      
      Mutate(child1, params.mutation_rate, encoding)
      Mutate(child2, params.mutation_rate, encoding)
      
      new_population.Append(child1)
      if Length(new_population) < params.population_size then
        new_population.Append(child2)
      end if
    end while
    
    population ← new_population[0:params.population_size]
  end for
  
  cover ← encoding.SolutionToCover(best_solution)
  return {best_solution, best_fitness, cover, is_valid}
end procedure
\end{verbatim}

\subsection{Simulated Annealing}

\textbf{Algorithm 2: Simulated Annealing for Minimum Vertex Cover}

\begin{verbatim}
procedure SimulatedAnnealing(problem, encoding, fitness, params)
  current ← RandomSolution(encoding)
  current_fitness ← Evaluate(current, fitness, encoding)
  best ← DeepCopy(current)
  best_fitness ← current_fitness
  
  temperature ← params.initial_temperature
  iteration ← 0
  
  while temperature > params.min_temperature AND iteration < params.max_iterations do
    for i = 1 to params.iterations_per_temperature do
      neighbor ← GetNeighbor(current, encoding)
      neighbor_fitness ← Evaluate(neighbor, fitness, encoding)
      
      accept_prob ← AcceptanceProbability(current_fitness, neighbor_fitness, temperature)
      
      if Random() < accept_prob then
        current ← neighbor
        current_fitness ← neighbor_fitness
        
        if current_fitness > best_fitness then
          best ← DeepCopy(current)
          best_fitness ← current_fitness
        end if
      end if
      
      iteration ← iteration + 1
      if iteration >= params.max_iterations then
        break
      end if
    end for
    
    temperature ← temperature × params.cooling_rate
  end while
  
  cover ← encoding.SolutionToCover(best)
  return {best, best_fitness, cover, is_valid}
end procedure

function AcceptanceProbability(current_fitness, neighbor_fitness, temperature)
  if neighbor_fitness ≥ current_fitness then
    return 1.0
  else
    return exp((neighbor_fitness - current_fitness) / temperature)
  end if
end function
\end{verbatim}

\subsection{Tabu Search}

\textbf{Algorithm 3: Tabu Search for Minimum Vertex Cover}

\begin{verbatim}
procedure TabuSearch(problem, encoding, fitness, params)
  current ← RandomSolution(encoding)
  current_fitness ← Evaluate(current, fitness, encoding)
  best ← DeepCopy(current)
  best_fitness ← current_fitness
  
  tabu_list ← EmptyQueue(max_size=params.tabu_list_size)
  tabu_list.Add(Hash(current))
  
  iteration ← 0
  no_improvement_count ← 0
  
  while iteration < params.max_iterations AND no_improvement_count < 100 do
    neighbors ← GenerateNeighborhood(current, encoding)
    
    if neighbors is empty then
      break
    end if
    
    best_neighbor ← None
    best_neighbor_fitness ← -∞
    
    for each neighbor in neighbors do
      neighbor_hash ← Hash(neighbor)
      is_tabu ← tabu_list.Contains(neighbor_hash)
      neighbor_fitness ← Evaluate(neighbor, fitness, encoding)
      
      aspiration_met ← (params.aspiration AND neighbor_fitness > best_fitness)
      
      if (NOT is_tabu AND neighbor_fitness > best_neighbor_fitness) OR
         aspiration_met then
        best_neighbor ← neighbor
        best_neighbor_fitness ← neighbor_fitness
      end if
    end for
    
    if best_neighbor is None then
      break
    end if
    
    current ← best_neighbor
    current_fitness ← best_neighbor_fitness
    tabu_list.Add(Hash(current))
    
    if current_fitness > best_fitness then
      best ← DeepCopy(current)
      best_fitness ← current_fitness
      no_improvement_count ← 0
    else
      no_improvement_count ← no_improvement_count + 1
    end if
    
    iteration ← iteration + 1
  end while
  
  cover ← encoding.SolutionToCover(best)
  return {best, best_fitness, cover, is_valid}
end procedure
\end{verbatim}

\section{Encoding Implementation}

\subsection{Binary Encoding Example}

\begin{lstlisting}[caption=Binary Encoding - Solution to Cover Conversion]
def binary_solution_to_cover(solution, num_nodes):
    """Convert binary vector to vertex cover."""
    cover = set()
    for i in range(num_nodes):
        if solution[i] == 1:
            cover.add(i)
    return cover

def binary_cover_to_solution(cover, num_nodes):
    """Convert cover to binary vector."""
    solution = [0] * num_nodes
    for node in cover:
        solution[node] = 1
    return solution

def binary_random_solution(num_nodes):
    """Generate random binary vector."""
    return [random.randint(0, 1) for _ in range(num_nodes)]

def binary_mutation(solution, mutation_rate, num_nodes):
    """Bit-flip mutation."""
    for i in range(num_nodes):
        if random.random() < mutation_rate:
            solution[i] = 1 - solution[i]

def binary_crossover(parent1, parent2):
    """Uniform crossover for binary vectors."""
    child1, child2 = [], []
    for i in range(len(parent1)):
        if random.random() < 0.5:
            child1.append(parent1[i])
            child2.append(parent2[i])
        else:
            child1.append(parent2[i])
            child2.append(parent1[i])
    return child1, child2
\end{lstlisting}

\subsection{Set-Based Encoding Example}

\begin{lstlisting}[caption=Set-Based Encoding - Solution to Cover Conversion]
def set_solution_to_cover(solution):
    """Convert sorted list to cover set."""
    return set(solution)

def set_cover_to_solution(cover):
    """Convert cover to sorted list."""
    return sorted(list(cover))

def set_random_solution(num_nodes):
    """Generate random set of nodes."""
    num_selected = random.randint(1, max(2, num_nodes // 2))
    nodes = random.sample(range(num_nodes), num_selected)
    return sorted(nodes)

def set_mutation(solution, mutation_rate, num_nodes):
    """Add/remove nodes from set."""
    if random.random() < mutation_rate / 2 and len(solution) > 0:
        # Remove random node
        idx = random.randint(0, len(solution) - 1)
        solution.pop(idx)
    
    if random.random() < mutation_rate / 2:
        # Add random node not in cover
        node = random.randint(0, num_nodes - 1)
        if node not in solution:
            solution.append(node)
            solution.sort()

def set_crossover(parent1, parent2):
    """Single-point crossover for variable-length sets."""
    # For variable-length, perform standard single-point split
    # and recombine (alternative: intersection/union-based)
    if len(parent1) <= 1:
        return list(parent1), list(parent2)
    
    point = random.randint(1, len(parent1) - 1)
    child1 = parent1[:point] + parent2[point:]
    child2 = parent2[:point] + parent1[point:]
    return child1, child2
\end{lstlisting}

\section{Fitness Function Implementation}

\begin{lstlisting}[caption=Fitness Function Examples]
def cover_size_minimization(cover, problem):
    """Fitness = 1 / (1 + normalized_size)"""
    size = len(cover)
    normalized_size = size / problem.num_nodes
    return 1.0 / (1.0 + normalized_size)

def constraint_penalty(cover, problem, penalty_weight=1.0):
    """
    Fitness with constraint penalty.
    Valid covers get positive fitness; invalid get penalized.
    """
    is_valid = problem.is_valid_cover(cover)
    uncovered = count_uncovered_edges(cover, problem)
    cover_size = len(cover)
    
    if is_valid:
        return 1.0 - (cover_size / problem.num_nodes) * 0.5
    else:
        penalty = penalty_weight * (uncovered + cover_size / problem.num_nodes)
        return max(0.0, 1.0 - penalty)

def edge_coverage_optimization(cover, problem, size_weight=0.3):
    """
    Multi-objective: maximize edge coverage, minimize cover size.
    Fitness = (covered_edges / total) - weight * (size / nodes)
    """
    covered = count_covered_edges(cover, problem)
    coverage_ratio = covered / problem.num_edges if problem.num_edges > 0 else 0
    
    size_penalty = (len(cover) / problem.num_nodes) * size_weight
    
    fitness = coverage_ratio - size_penalty
    return max(0.0, fitness)

def count_uncovered_edges(cover, problem):
    """Count edges not covered by solution."""
    uncovered = 0
    for u, v in problem.edges:
        if u not in cover and v not in cover:
            uncovered += 1
    return uncovered

def count_covered_edges(cover, problem):
    """Count edges covered by solution."""
    covered = 0
    for u, v in problem.edges:
        if u in cover or v in cover:
            covered += 1
    return covered
\end{lstlisting}

\section{Experimental Framework}

\begin{lstlisting}[caption=Main Experiment Loop Structure]
def run_experiments(num_runs=5):
    """Run full experimental suite."""
    instances = generate_benchmark_instances()
    results = []
    
    for problem, instance_name in instances:
        print(f"Processing {instance_name}...")
        
        encodings = [
            BinaryEncoding(),
            SetEncoding(),
            EdgeCentricEncoding(problem.edges)
        ]
        
        fitness_functions = [
            CoverSizeMinimization(problem),
            ConstraintPenalty(problem, penalty_weight=1.0),
            EdgeCoverageOptimization(problem, size_weight=0.3)
        ]
        
        for run_id in range(num_runs):
            for encoding in encodings:
                for fitness_func in fitness_functions:
                    # Genetic Algorithm
                    ga = GeneticAlgorithm(
                        problem, encoding, fitness_func,
                        params=GAParams(population_size=100, generations=300)
                    )
                    result_ga = ga.run()
                    results.append({
                        'instance': instance_name,
                        'algorithm': 'GA',
                        'encoding': encoding.get_name(),
                        'fitness_func': fitness_func.get_name(),
                        'run': run_id,
                        'cover_size': result_ga['best_cover_size'],
                        'is_valid': result_ga['is_valid'],
                        'fitness': result_ga['best_fitness']
                    })
                    
                    # Simulated Annealing
                    sa = SimulatedAnnealing(
                        problem, encoding, fitness_func,
                        params=SAParams(initial_temperature=100.0, max_iterations=5000)
                    )
                    result_sa = sa.run()
                    results.append({...})  # Similar structure
                    
                    # Tabu Search
                    ts = TabuSearch(
                        problem, encoding, fitness_func,
                        params=TSParams(tabu_list_size=50, max_iterations=5000)
                    )
                    result_ts = ts.run()
                    results.append({...})  # Similar structure
    
    # Save and analyze results
    save_to_csv(results, 'results.csv')
    print_summary_statistics(results)
    return results
\end{lstlisting}

\section{Instance Generation}

\begin{lstlisting}[caption=Benchmark Instance Generation]
import networkx as nx
import random

def generate_erdos_renyi_instance(num_nodes, edge_probability, seed=None):
    """Generate random graph using ER model."""
    if seed:
        random.seed(seed)
    
    graph = nx.erdos_renyi_graph(num_nodes, edge_probability)
    return MinimumVertexCoverProblem(graph)

def generate_scale_free_instance(num_nodes, m=2, seed=None):
    """Generate scale-free graph (Barabasi-Albert model)."""
    if seed:
        random.seed(seed)
    
    graph = nx.barabasi_albert_graph(num_nodes, m)
    return MinimumVertexCoverProblem(graph)

def generate_benchmark_suite():
    """Generate standard benchmark instances."""
    instances = []
    
    # Small ER instance
    instances.append((
        generate_erdos_renyi_instance(20, 0.3, seed=42),
        "small_20nodes"
    ))
    
    # Medium ER instance
    instances.append((
        generate_erdos_renyi_instance(50, 0.25, seed=43),
        "medium_50nodes"
    ))
    
    # Large ER instance
    instances.append((
        generate_erdos_renyi_instance(100, 0.15, seed=44),
        "large_100nodes"
    ))
    
    # Scale-free instance
    instances.append((
        generate_scale_free_instance(50, m=3, seed=45),
        "scale_free_50nodes"
    ))
    
    return instances
\end{lstlisting}

\section{Key Implementation Details}

\subsection{Parameter Selection Rationale}

\begin{enumerate}
    \item \textbf{GA Population Size (100)}: Balances diversity against computational cost. Too small (20-30) causes premature convergence; too large (500+) slows iterations.
    
    \item \textbf{GA Generations (300)}: Approximately 30,000 fitness evaluations. Provides reasonable runtime while avoiding convergence plateau.
    
    \item \textbf{SA Initial Temperature (100.0)}: Calibrated so that $\exp(-100/100) = \exp(-1) \approx 0.37$, giving ~37\% acceptance of random moves initially.
    
    \item \textbf{SA Cooling Rate (0.95)}: Geometric schedule slower than 0.9 (too aggressive) but faster than 0.99 (too slow). Reaches min temperature in ~90 iterations.
    
    \item \textbf{TS Tabu List Size (50)}: Approximately 10\% of solution space (for 20-100 node graphs). Prevents recent cycling without over-constraining.
\end{enumerate}

\subsection{Reproducibility}

All experiments use fixed random seeds:
\begin{itemize}
    \item Instance generation: seeds 42-45
    \item Algorithm runs: Python random.seed() and numpy.random.seed() set before each run
    \item Enables exact replication of reported results
\end{itemize}

\end{document}
